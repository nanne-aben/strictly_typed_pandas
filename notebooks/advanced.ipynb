{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd021955bae40816b58329a864495bd83642121ab031d49eff86d34b7b0569c6cea",
   "display_name": "Python 3.8.8 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "source": [
    "# Subclassing schemas\n",
    "\n",
    "Subclassing schemas is a useful pattern for pipelines where every next function adds a few columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strictly_typed_pandas import DataSet\n",
    "\n",
    "class SchemaA:\n",
    "    name: str\n",
    "\n",
    "class SchemaB(SchemaA):\n",
    "    id: int\n",
    "\n",
    "df = DataSet[SchemaA]({\"name\": [\"John\", \"Jane\", \"Jack\"]})\n",
    "\n",
    "def foo(df: DataSet[SchemaA]) -> DataSet[SchemaB]:\n",
    "    return (\n",
    "        df.assign(id=lambda df: range(df.shape[0]))\n",
    "        .pipe(DataSet[SchemaB])\n",
    "    )"
   ]
  },
  {
   "source": [
    "Similarly, you can use it when merging (or joining or concatenating) two datasets together."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  name             job\n",
       "0   1  John  Data Scientist\n",
       "1   2  Jane  Data Scientist\n",
       "2   3  Jack  Data Scientist"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>job</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>John</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jane</td>\n      <td>Data Scientist</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Jack</td>\n      <td>Data Scientist</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "class SchemaA:\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "class SchemaB:\n",
    "    id: int\n",
    "    job: str\n",
    "\n",
    "class SchemaAB(SchemaA, SchemaB):\n",
    "    pass\n",
    "\n",
    "df1 = DataSet[SchemaA]({\"id\": [1, 2, 3], \"name\": [\"John\", \"Jane\", \"Jack\"]})\n",
    "df2 = DataSet[SchemaB]({\"id\": [1, 2, 3], \"job\": \"Data Scientist\"})\n",
    "(\n",
    "    df1.merge(df2, on=\"id\")\n",
    "    .pipe(DataSet[SchemaAB])\n",
    ")"
   ]
  },
  {
   "source": [
    "# Creating an empty DataSet\n",
    "Sometimes it's useful to create a DataSet without any rows. This can be easily done as follows:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataSet\n",
       "Columns: [id, name]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "class Schema:\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "DataSet[Schema]()"
   ]
  },
  {
   "source": [
    "# Support for numpy and pandas data types\n",
    "We also support using numpy types and pandas types, as well as `typing.Any`. If you miss support for any other data type, drop us a line and we'll see if we can add it!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "name         string\n",
       "money       float64\n",
       "eggs          int64\n",
       "potatoes     object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "class Schema:\n",
    "    name: pd.StringDtype\n",
    "    money: np.float64\n",
    "    eggs: np.int64\n",
    "    potatoes: Any\n",
    "\n",
    "df = DataSet[Schema](\n",
    "    {\n",
    "        \"name\": pd.Series([\"John\", \"Jane\", \"Jack\"], dtype=\"string\"),\n",
    "        \"money\": pd.Series([100.50, 1000.23, 123.45], dtype=np.float64),\n",
    "        \"eggs\": pd.Series([1, 2, 3], dtype=np.int64),\n",
    "        \"potatoes\": [\"1\", 0, np.nan]\n",
    "    }\n",
    ")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "source": [
    "# IndexedDataSet\n",
    "\n",
    "If you'd like to also strictly type the index, you can use the IndexedDataSet class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strictly_typed_pandas import IndexedDataSet\n",
    "\n",
    "class IndexSchema:\n",
    "    id: int\n",
    "    job: str\n",
    "\n",
    "class DataSchema:\n",
    "    name: str\n",
    "\n",
    "df = (\n",
    "    pd.DataFrame({\"id\": [1, 2, 3], \"name\": [\"John\", \"Jane\", \"Jack\"], \"job\": \"Data Scientist\"})\n",
    "    .set_index([\"id\", \"job\"])\n",
    "    .pipe(IndexedDataSet[IndexSchema, DataSchema])\n",
    ")"
   ]
  },
  {
   "source": [
    "# Reusing a variable (e.g. `df`) with different schemas\n",
    "Sometimes when building a pipeline, it's useful to reuse a variable (e.g. `df`) with different schemas. If we do that in the following way however, we'll get a mypy error."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaA:\n",
    "    name: str\n",
    "\n",
    "class SchemaB(SchemaA):\n",
    "    id: int\n",
    "\n",
    "def foo(df: DataSet[SchemaA]) -> DataSet[SchemaB]:\n",
    "    return (\n",
    "        df.assign(id=1)\n",
    "        .pipe(DataSet[SchemaB])\n",
    "    )\n",
    "\n",
    "df = DataSet[SchemaA]({\"name\": [\"John\", \"Jane\", \"Jack\"]})\n",
    "df = foo(df)\n",
    "# mypy(error): Incompatible types in assignment (expression has type \"DataSet[SchemaB]\", variable has type \"DataSet[SchemaA]\")"
   ]
  },
  {
   "source": [
    "To avoid this error, we need to declare that `df` will be of the type `DataSet` (implying the the schema may be different at different points)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataSet\n",
    "df = DataSet[SchemaA]({\"name\": [\"John\", \"Jane\", \"Jack\"]})\n",
    "df = foo(df)"
   ]
  },
  {
   "source": [
    "# No cloning\n",
    "\n",
    "When a `DataFrame` is cast to a `DataSet`, the underlying data isn't cloned (unless you use `DataSet[Schema](..., copy=True)`). This is great for memory purposes, but it does require some caution. For example, consider the following pandas script:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "Name: name, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"id\": [1, 2, 3], \"name\": [\"John\", \"Jane\", \"Jack\"]})\n",
    "df2 = pd.DataFrame(df1)\n",
    "df1.name = [1, 2, 3]\n",
    "df2.name"
   ]
  },
  {
   "source": [
    "Here, `df1` and `df2` essentially point to the same data, so changing one of them changes the other one too. This behaviour extends to `DataSet` as well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "Name: name, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "class Schema:\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "df1 = pd.DataFrame({\"id\": [1, 2, 3], \"name\": [\"John\", \"Jane\", \"Jack\"]})\n",
    "df2 = DataSet[Schema](df1)\n",
    "\n",
    "df1.name = [1, 2, 3]\n",
    "df2.name"
   ]
  },
  {
   "source": [
    "This is somewhat problematic, because we now made a change to the schema, without any error thrown whatsoever! However:\n",
    "\n",
    "* I essentially can't stop you from doing this (apart from forcing `DataSet` to copy the data when created, which I won't).\n",
    "* If this happens in your code, you have bigger problems that type checking.\n",
    "\n",
    "So the bottomline is: be careful when dealing with pointers!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}